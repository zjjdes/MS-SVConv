{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "<torch.cuda.device object at 0x7fd1509b9f40>\n",
      "1\n",
      "GeForce RTX 3070\n",
      "8366915584\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_properties(0).total_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8366915584\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_per_process_memory_fraction(0.5, 0)\n",
    "torch.cuda.empty_cache()\n",
    "total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "\n",
    "# less than 0.5 will be ok:\n",
    "tmp_tensor = torch.empty(int(total_memory * 0.499), dtype=torch.int8, device='cuda')\n",
    "del tmp_tensor\n",
    "torch.cuda.empty_cache()\n",
    "# this allocation will raise a OOM:\n",
    "torch.empty(total_memory // 2, dtype=torch.int8, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[180101.]\n",
      " [180118.]\n",
      " [180288.]\n",
      " [180322.]\n",
      " [180323.]\n",
      " [180513.]\n",
      " [180516.]\n",
      " [180517.]\n",
      " [180522.]\n",
      " [180524.]\n",
      " [180527.]\n",
      " [180542.]\n",
      " [180546.]\n",
      " [180548.]\n",
      " [180780.]\n",
      " [181034.]\n",
      " [181315.]\n",
      " [181369.]\n",
      " [181377.]\n",
      " [181378.]\n",
      " [181391.]\n",
      " [181392.]\n",
      " [181398.]\n",
      " [181400.]\n",
      " [181409.]\n",
      " [181531.]\n",
      " [181530.]\n",
      " [181579.]\n",
      " [181580.]\n",
      " [181585.]\n",
      " [181586.]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dir = '../../../KITTI_partial_10s/keypoints_ETH_3000_0.01_0.1/'\n",
    "\n",
    "rovs = [x[0] for x in os.walk(dir)]\n",
    "\n",
    "empty = np.empty((0, 1))\n",
    "\n",
    "for f in rovs:\n",
    "  if len(os.listdir(f)) == 0:\n",
    "      empty = np.vstack((empty, np.array([int(f[-6:])])))\n",
    "\n",
    "print(empty)\n",
    "\n",
    "np.savetxt('../../../KITTI_partial_10s/keypoints_ETH_3000_0.01_0.1/not_processed.csv', empty, fmt='%s', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6735002e15b51b6d703c89f82108674911e30b5653ed2ad83f3e0f88fc4e377"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('torch-points3d-w-BPrO1f-py3.8': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
